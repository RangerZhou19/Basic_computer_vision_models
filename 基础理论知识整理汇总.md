# 深度神经网络和计算机视觉的基础知识
###### 对于深度学习，可以参考 周志华老师于专知上文章"关于深度学习的一点思考"

## 视觉算法的基础知识


### 1 传统视觉算法基础🚲

#### 1.1 边缘检测

#### 1.2 形态学分析

### 2 深度学习视觉相关🏎

[知乎总结深度学习下视觉基础知识点](https://zhuanlan.zhihu.com/p/58776542)

#### 2.1 视觉四大基本任务介绍(分类、定位、检测、分割)

  ###### 计算机视觉旨在识别和理解图像/视频中的内容。Vision诞生于1966年的MIT AI Group的"the summer vision project"。当时，人工智能其他分支的研究已经有一些初步成果，由于人类自己本身可以轻易地进行视觉认知，MIT的教授们希望通过一个暑假项目来解决计算机视觉问题。当然，计算机视觉问题没有被一个暑期内解决，并经过50余年的发展已成为一个十分活跃的研究领域。
  
  ###### 计算机视觉的难点在于语义鸿沟，这个现象不仅出现在计算机视觉领域，Moravec悖论发现，高级的推理只需要非常少的计算资源，而低级的对外界的感知却需要极大的计算资源。要让计算机如成人般地下棋是相对容易的，但是要让电脑有如一岁小孩般的感知和行动能力却是相当困难甚至是不可能的。
  
  ###### 语义鸿沟：人类可以轻松地从图像中识别出目标，而计算机看到的图像是一组0到255之间的整数。
  
  ###### 计算机视觉任务中的困难：拍摄视角的变化、目标占据图像的比例变化、关照变化、背景融合、目标形变、遮挡
  
  ###### 计算机视觉顶级会议和期刊：CVPR ICCV ECCV ICLR; IJCV TPAMI 
  
  ###### 卷积神经网络(convolutional neural networks, CNN)基本介绍
  ###### 经典的多层感知机由一系列全连接层组成，卷积神经网络除 全连接层以外，还有卷积层和池化层
  ###### (1) 卷积层
  ######     卷积是局部连接、权重共享版的全连接层，这两个特性使得权重参数量大大降低。卷积层中的权值通常被成为滤波器或卷积核。使用卷积层的原因，用卷积层代替全连接层可以减少网络的权值，从而降低过拟合的风险
  ######     局部连接：在全连接层中，每个输出通过权值(weight)和所有输入相连。在视觉识别中，关键性的图像特征、边缘、角点等只占据了整张图像的一小部分，图像中相距很远的两个像素之间有相互影响的可能性很小。因此，在卷积层中，每个输出神经元在通道方向保持全连接，而在空间方向上只和一小部分输入神经元相连。
  ######     
  
  
  
  


#### 2.2 经典卷积网络



#### 2.3 卷积、空洞卷积


#### 2.4 正则化


#### 2.5 全卷积网络


#### 2.6 1x1卷积核


#### 2.7 感受野


#### 2.8 常见损失


#### 2.9 优化算法


#### 2.10 concat和add的区别


#### 2.11 注意力机制


#### 2.12 CNN RNN DNN


#### 2.13 边框回归(Bounding Box Regression)


#### 2.14 非极大值回归(NMS, Soft NMS)


#### 2.15 激活函数


#### 2.16 评价函数


#### 2.17 Batch size的选择


#### 2.18 图卷积网络 Graph Convolutional Network (GCN)


#### 2.19 解释深度学习中的梯度消失和梯度爆炸的原因，及其解决方法


#### 2.20 网络权重初始化方法


#### 2.21 方向传播理解  warmup策略的理论解释


******
## 图像处理基础知识
###### 参见视频: [图像分析基础](https://www.bilibili.com/video/BV1wL411s7NX?spm_id_from=333.999.0.0) 
###### 笔记参见：[图像处理与图像分析基础笔记](https://github.com/RangerZhou19/Basic_computer_vision_models/blob/main/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%92%8C%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80.md)













